{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GbR61GoANo_J"
   },
   "source": [
    "# **CSE 574 Project**\n",
    "## *Real vs Fake Classification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMgXlUNrN9MV"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "from google.colab import drive\n",
    "from google.colab import output as colab_op\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "import cv2\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from random import random, choice, shuffle\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fw4xtylxiXEA"
   },
   "source": [
    "### *Data preprocessing, exploration and prep for training.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "kuJ6UVQ6EmV2",
    "outputId": "c28368b4-7e69-400c-f9e2-2e993c0d4728"
   },
   "outputs": [],
   "source": [
    "# mount drive to session\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0of2EIMGaJi"
   },
   "source": [
    "### Options for managing data and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CF0W0dKZiVfT"
   },
   "outputs": [],
   "source": [
    "# options\n",
    "shuffle = True\n",
    "sampler = None\n",
    "train = True\n",
    "# path options\n",
    "\n",
    "# classes = [each.split('progan/')[1].strip('/') for each in glob.glob('/content/drive/My Drive/Colab Notebooks/CNN_synth_testset/progan/*')]\n",
    "# dataroot = '/content/drive/My Drive/Colab Notebooks/CNN_synth_testset/progan/'\n",
    "\n",
    "classes = []\n",
    "dataroot = '/content/drive/My Drive/Colab Notebooks/'\n",
    "\n",
    "# augmentation options\n",
    "blur_prob = 0.1\n",
    "blur_sig = [0.5]\n",
    "jpg_prob = 0.1\n",
    "jpg_method = ['cv2']\n",
    "jpg_qual = [75]\n",
    "# preprocessing options\n",
    "resize = 256\n",
    "num_threads = 4\n",
    "crop_size = 224\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PwPIGoopGpHQ"
   },
   "source": [
    "### Data augmentaion strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChyPz6ZKiVbj"
   },
   "outputs": [],
   "source": [
    "rz_dict = {'bilinear': Image.BILINEAR,\n",
    "           'bicubic': Image.BICUBIC,\n",
    "           'lanczos': Image.LANCZOS,\n",
    "           'nearest': Image.NEAREST}\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:, :, ::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:, :, ::-1]\n",
    "\n",
    "\n",
    "def pil_jpg(img, compress_val):\n",
    "    out = BytesIO()\n",
    "    img = Image.fromarray(img)\n",
    "    img.save(out, format='jpeg', quality=compress_val)\n",
    "    img = Image.open(out)\n",
    "    # load from memory before ByteIO closes\n",
    "    img = np.array(img)\n",
    "    out.close()\n",
    "    return img\n",
    "\n",
    "jpeg_dict = {'cv2': cv2_jpg, 'pil': pil_jpg}\n",
    "\n",
    "def jpeg_from_key(img, compress_val, key):\n",
    "    method = jpeg_dict[key]\n",
    "    return method(img, compress_val)\n",
    "\n",
    "\n",
    "def sample_discrete(s):\n",
    "    if len(s) == 1:\n",
    "        return s[0]\n",
    "    return choice(s)\n",
    "\n",
    "\n",
    "def custom_resize(img):\n",
    "    interp = sample_discrete([\"bilinear\"])\n",
    "    return TF.resize(img, resize, interpolation=rz_dict[interp])\n",
    "\n",
    "\n",
    "def sample_continuous(s):\n",
    "    if len(s) == 1:\n",
    "        return s[0]\n",
    "    if len(s) == 2:\n",
    "        rg = s[1] - s[0]\n",
    "        return random() * rg + s[0]\n",
    "    raise ValueError(\"Length of iterable s should be 1 or 2.\")\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:, :, 0], output=img[:, :, 0], sigma=sigma)\n",
    "    gaussian_filter(img[:, :, 1], output=img[:, :, 1], sigma=sigma)\n",
    "    gaussian_filter(img[:, :, 2], output=img[:, :, 2], sigma=sigma)\n",
    "\n",
    "\n",
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random() < blur_prob:\n",
    "        sig = sample_continuous(blur_sig)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random() < jpg_prob:\n",
    "        method = sample_discrete(jpg_method)\n",
    "        qual = sample_discrete(jpg_qual)\n",
    "        img = jpeg_from_key(img, qual, method)\n",
    "\n",
    "    return Image.fromarray(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpKToNvuGBY3"
   },
   "source": [
    "### *Dataset creation code*\n",
    "  - We are using pytorch's torchvision package for loading the the images and converting them into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8WSyYvzGFGL"
   },
   "outputs": [],
   "source": [
    "def dataset_folder(root):\n",
    "  crop_func = transforms.RandomCrop if train else transforms.CenterCrop\n",
    "  if train:\n",
    "      flip_func = transforms.RandomHorizontalFlip()\n",
    "  else:\n",
    "      flip_func = transforms.Lambda(lambda img: img)\n",
    "  # if not train:\n",
    "  #     rz_func = transforms.Lambda(lambda img: img)\n",
    "  # else:\n",
    "  #     rz_func = transforms.Lambda(lambda img: custom_resize(img))\n",
    "  rz_func = transforms.Lambda(lambda img: custom_resize(img))\n",
    "\n",
    "  dset = datasets.ImageFolder(root, transforms.Compose([\n",
    "          rz_func,\n",
    "          transforms.Lambda(lambda img: data_augment(img)),\n",
    "          crop_func(crop_size),\n",
    "          flip_func,\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "      ]))\n",
    "  return dset\n",
    "\n",
    "\n",
    "def get_dataloader(test=False):\n",
    "    global train, classes\n",
    "    if test:\n",
    "      train = False\n",
    "      classes = ['test_whichfaceisreal']\n",
    "    else:\n",
    "      train = True\n",
    "      classes = ['whichfaceisreal']\n",
    "    dset_lst = []\n",
    "    for cls in classes:\n",
    "        root = dataroot + '/' + cls\n",
    "        dset = dataset_folder(root)\n",
    "        dset_lst.append(dset)\n",
    "    dataset = torch.utils.data.ConcatDataset(dset_lst)\n",
    "    return torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=shuffle,\n",
    "                                              sampler=sampler,\n",
    "                                              num_workers=num_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JBEG6KT8HpC"
   },
   "source": [
    "### *Model architecture description*\n",
    "  - We are using pytorch's implementaion of resnet50.\n",
    "  - If we choose to use pretrained weights, we will be using the weights provided by pytorch which is trained on imagenet.\n",
    "  - We have opted to freeze all the layers except the 4th layer and the FC layer of the resnet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KM7fX5A_TE1G"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        # Conv_1 Layers\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, not_freeze=None, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = model_zoo.load_url('https://download.pytorch.org/models/resnet50-19c8e357.pth')\n",
    "        state_dict['fc.weight'] = state_dict['fc.weight'][[kwargs.get('num_classes', 1)]]\n",
    "        state_dict['fc.bias'] = state_dict['fc.bias'][:kwargs.get('num_classes', 1)]\n",
    "        model.load_state_dict(state_dict)\n",
    "        if not_freeze:\n",
    "            for name, child in model.named_children():\n",
    "                if name not in not_freeze:\n",
    "                    for name2, params in child.named_parameters():\n",
    "                        params.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2qZ71UuU-Zr"
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def show(_img):\n",
    "    npimg = _img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    pred_class = []\n",
    "    prob = []\n",
    "    with torch.no_grad():\n",
    "      output = net(images).detach().cpu().sigmoid().squeeze().tolist()\n",
    "    for p in output:\n",
    "      if p>0.5:\n",
    "        pred_class.append('fake')\n",
    "        prob.append(p)\n",
    "      else:\n",
    "        pred_class.append('real')\n",
    "        prob.append(1-p)\n",
    "    \n",
    "    return pred_class, prob\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    _classes = ['real', 'fake']\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx].cpu())\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            preds[idx],\n",
    "            probs[idx] * 100.0,\n",
    "            _classes[labels[idx].cpu()]),\n",
    "                    color=(\"green\" if preds[idx]==_classes[labels[idx].item()] else \"red\"))\n",
    "    return fig\n",
    "\n",
    "\n",
    "def validate(model, data_loader_test):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_true, y_pred = [], []\n",
    "        for img, label in data_loader_test:\n",
    "            in_tens = img.cuda()\n",
    "            y_pred.extend(model(in_tens).sigmoid().flatten().tolist())\n",
    "            y_true.extend(label.flatten().tolist())\n",
    "\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    r_acc = accuracy_score(y_true[y_true == 0], y_pred[y_true == 0] > 0.5)\n",
    "    f_acc = accuracy_score(y_true[y_true == 1], y_pred[y_true == 1] > 0.5)\n",
    "    acc = accuracy_score(y_true, y_pred > 0.5)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    return acc, ap, r_acc, f_acc, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWrvSQgiVZXW"
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs, lr, optimizer, criterion, data_loader, data_loader_test):\n",
    "  running_loss = 0.0\n",
    "  # override the learning rate\n",
    "  if lr != learning_rate:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    # decay the learning rate for every two epochs\n",
    "    if epoch%2==0 and epoch and epoch < 5:\n",
    "      lr = lr/10\n",
    "      for param_group in optimizer.param_groups:\n",
    "          param_group['lr'] = lr\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(data_loader):\n",
    "      inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "      optimizer.zero_grad()\n",
    "      output = model(inputs)\n",
    "\n",
    "      loss = criterion(output, labels.type_as(output).unsqueeze(1))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item()\n",
    "      colab_op.clear('status_text')\n",
    "      with colab_op.use_tags('status_text'):\n",
    "        print(f\"epoch: {epoch}, batch:{batch_idx}, loss: {loss.item()}, lr: {lr}\")\n",
    "\n",
    "    writer.add_scalar(f'TrainLoss', running_loss/(len(data_loader)*batch_idx), epoch)\n",
    "    writer.flush()\n",
    "    running_loss = 0.0\n",
    "    acc, ap, _, _, _, _ = validate(model, data_loader_test)\n",
    "    writer.add_scalar('Accuracy', acc*100, epoch)\n",
    "    writer.add_scalar('AP', ap, epoch)\n",
    "    writer.add_figure('predictions vs. actuals', plot_classes_preds(model, inputs, labels), global_step=epoch * len(data_loader) + batch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPKtp6LBs4z8"
   },
   "outputs": [],
   "source": [
    "# training options\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GbBZZKUUIFbq"
   },
   "source": [
    "### *We have used tensorboard to keep track of the training metrics as it provides an interactive UI.*\n",
    "  - We can also use ngrok to monitor the progress remotely as tensorboard is a webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrdGtPkq_x7h"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/drive/My\\ Drive/Colab\\ Notebooks/runs\n",
    "%tensorboard --logdir /content/drive/My\\ Drive/Colab\\ Notebooks/runs\n",
    "writer = SummaryWriter('/content/drive/My Drive/Colab Notebooks/runs')\n",
    "# data loaders\n",
    "data_loader = get_dataloader()\n",
    "data_loader_test = get_dataloader(test=True)\n",
    "# training params\n",
    "model = resnet50(pretrained=True, not_freeze=['layer4', 'fc'], num_classes=1).cuda().train()\n",
    "lr = learning_rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train_model(model, 10, lr, optimizer, criterion, data_loader, data_loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qf73K-ZwJTz4"
   },
   "source": [
    "### Plotting the ROC and AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lh7VPHIt3Qk"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "colab_type": "code",
    "id": "j4nPFXEFHZ4e",
    "outputId": "a22e9ca7-4d34-420e-d8af-f3642d584731"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                         roc_auc_score - 0.98595'"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        y_true, y_pred = [], []\n",
    "        for img, label in data_loader_test:\n",
    "            in_tens = img.cuda()\n",
    "            y_pred.extend(model(in_tens).sigmoid().flatten().tolist())\n",
    "            y_true.extend(label.flatten().tolist())\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "# plot the roc curve for the model\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.plot(fpr, tpr, marker='.', label='ROC Curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "f'                         roc_auc_score - {roc_auc_score(y_true, y_pred)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W8WQ86XZE9GA"
   },
   "source": [
    "### The following code is to just to move around data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kD5Bu-l8_Q0k"
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lv3DVjHG_mD3"
   },
   "outputs": [],
   "source": [
    "# fake = glob.glob('/content/drive/My Drive/Colab Notebooks/whichfaceisreal/1_fake/*')\n",
    "# real = glob.glob('/content/drive/My Drive/Colab Notebooks/whichfaceisreal/0_real/*')\n",
    "# shuffle(fake)\n",
    "# shuffle(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIXwNB9t_m14"
   },
   "outputs": [],
   "source": [
    "# mkdir test_whichfaceisreal\n",
    "# cd test_whichfaceisreal\n",
    "# !mkdir 1_fake\n",
    "# !mkdir 0_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M3O1Rn6HBKGL"
   },
   "outputs": [],
   "source": [
    "# for i in real[:200]:\n",
    "#   shutil.move(i, \"0_real\")\n",
    "\n",
    "# for i in fake[:200]:\n",
    "#   shutil.move(i, \"1_fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lyhFVNh1DS4i"
   },
   "source": [
    "### Server code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZeCwnTU7EFa5"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "import cv2\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from random import random, choice\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 224\n",
    "resize = 256\n",
    "\n",
    "def custom_resize(img):\n",
    "    interp = \"bilinear\"\n",
    "    return TF.resize(img, resize, interpolation=Image.BILINEAR)\n",
    "\n",
    "loader = transforms.Compose([\n",
    "          transforms.Lambda(lambda img: custom_resize(img)),\n",
    "#           transforms.Lambda(lambda img: data_augment(img)),\n",
    "          transforms.CenterCrop(crop_size),\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "      ])\n",
    "\n",
    "def image_loader(img_path):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(img_path)\n",
    "    image = loader(image).float().unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        # Conv_1 Layers\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet50_inference(**kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50_inference(num_classes=1)\n",
    "model.load_state_dict(torch.load(\"/Users/nikhilvasudeva/Downloads/CSE574Project/model.torch\", map_location=torch.device('cpu')))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flask_cors.extension.CORS at 0x111dedd50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_paths = glob(\"/Users/nikhilvasudeva/Downloads/CSE574Project/data/1_fake/*\")\n",
    "real_paths = glob(\"/Users/nikhilvasudeva/Downloads/CSE574Project/data/0_real/*\")\n",
    "\n",
    "@app.route(\"/get_predicitons\", methods=[\"GET\"])\n",
    "def get_response():\n",
    "    fake_img = choice(fake_paths)\n",
    "    real_img = choice(real_paths)\n",
    "    img1 = choice([fake_img, real_img])\n",
    "    img2 = real_img\n",
    "    fake = \"img1\"\n",
    "\n",
    "    if img1 == real_img:\n",
    "        fake = \"img2\"\n",
    "        img2 = fake_img\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image_loader(fake_img))\n",
    "        probs = (output).sigmoid().flatten().item()\n",
    "\n",
    "    if probs > 0.5:\n",
    "        model_pred = fake\n",
    "    else:\n",
    "        probs = 1-probs\n",
    "        if fake == \"img1\":\n",
    "            model_pred = \"img2\"\n",
    "        else:\n",
    "            model_pred = \"img1\"\n",
    "\n",
    "    print({\"img1\": img1, \"img2\": img2, \"fake\": fake, \"model\": {\"fake\": model_pred, \"probability\": int(probs*100)}})\n",
    "    return jsonify({\"img1\": img1, \"img2\": img2, \"fake\": fake, \"model\": {\"fake\": model_pred, \"probability\": int(probs*100)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [04/May/2020 17:16:24] \"GET /get_predicitons HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img1': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/1_fake/image-2019-02-17_022406.jpeg', 'img2': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/0_real/00186.jpeg', 'fake': 'img1', 'model': {'fake': 'img1', 'probability': 99}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/May/2020 17:39:07] \"GET /get_predicitons HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img1': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/1_fake/image-2019-02-17_025658.jpeg', 'img2': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/0_real/00801.jpeg', 'fake': 'img1', 'model': {'fake': 'img2', 'probability': 68}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/May/2020 17:39:33] \"GET /get_predicitons HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img1': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/1_fake/image-2019-02-17_020024.jpeg', 'img2': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/0_real/00243.jpeg', 'fake': 'img1', 'model': {'fake': 'img1', 'probability': 98}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/May/2020 17:45:10] \"GET /get_predicitons HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img1': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/0_real/00798.jpeg', 'img2': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/1_fake/image-2019-02-17_023433.jpeg', 'fake': 'img2', 'model': {'fake': 'img2', 'probability': 99}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/May/2020 17:57:29] \"GET /get_predicitons HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img1': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/1_fake/image-2019-02-17_022838.jpeg', 'img2': '/Users/nikhilvasudeva/Downloads/CSE574Project/data/0_real/00297.jpeg', 'fake': 'img1', 'model': {'fake': 'img1', 'probability': 99}}\n"
     ]
    }
   ],
   "source": [
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CSE574_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
