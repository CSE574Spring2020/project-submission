{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine-belajar_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHavyNFKWOBp",
        "colab_type": "text"
      },
      "source": [
        "Heavily inspired by: https://towardsdatascience.com/sentiment-analysis-using-rnns-lstm-60871fa6aeba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHN0-k_cpVbw",
        "colab_type": "text"
      },
      "source": [
        "0. Have Tensorflow version 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJwvl3_fpHfW",
        "colab_type": "code",
        "outputId": "85a54365-2109-48d8-8918-66b84058f35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 74kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.28.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0rc4\n",
            "    Uninstalling tensorflow-2.2.0rc4:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc4\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWYY_uKOWWW_",
        "colab_type": "text"
      },
      "source": [
        "1. Clone cleaned Indonesian tweets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfywddqDVxcR",
        "colab_type": "code",
        "outputId": "beb9d299-6625-424b-eccc-0c68e82f99f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "!git clone https://github.com/ridife/dataset-idsa.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dataset-idsa'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 6\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE8am070W9TS",
        "colab_type": "text"
      },
      "source": [
        "2. Import packages, load data, and lightly process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er18wDAuW9hv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "05bd3cd7-7788-4dd8-f8a9-c6d7de383239"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from string import punctuation\n",
        "from collections import Counter"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfvDICYjXJUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = []\n",
        "sentiments = []\n",
        "with open('/content/dataset-idsa/Indonesian Sentiment Twitter Dataset Labeled.csv', 'r', encoding='utf-8') as inf, open('poli_data_format.csv', 'r', encoding='utf-8') as inf2:\n",
        "  for f in [inf, inf2]:\n",
        "    is_header = True\n",
        "    for tweet in f.readlines():\n",
        "      if is_header: # skip first line\n",
        "        is_header = False\n",
        "        continue\n",
        "      if tweet.startswith('0'):\n",
        "        continue # ignore neutral tweets\n",
        "      elif tweet.startswith('-1'):\n",
        "        sentiments.append(tweet[:2])\n",
        "        tweet = tweet[3:-1]\n",
        "      else:\n",
        "        sentiments.append(tweet[:1])\n",
        "        tweet = tweet[2:-1]\n",
        "      tweet = ''.join([char for char in tweet if char not in punctuation])\n",
        "      tweets.append(tweet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXuc0X-KlJ-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.array([1 if sentiment == '1' else 0 for sentiment in sentiments])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhodBS_edowJ",
        "colab_type": "text"
      },
      "source": [
        "3. Get vocabulary of tweets, mapping words to integers, so that we may convert tweets into integers to be passed onto the network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw-1FtniXcaa",
        "colab_type": "code",
        "outputId": "73c88c2e-5e1e-4fef-8628-e00f39bddaee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "plain_text = ' '.join([tweet for tweet in tweets])\n",
        "words = plain_text.split()\n",
        "\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: i for i, word in enumerate(vocab, 1)}\n",
        "\n",
        "tweets_ints = []\n",
        "for tweet in tweets:\n",
        "  tweets_ints.append([vocab_to_int[word] for word in tweet.split()])\n",
        "\n",
        "tweets_lens = Counter([len(x) for x in tweets_ints])\n",
        "tweets_ints = [tweet[:max(tweets_lens)] for tweet in tweets_ints]\n",
        "print(\"Maximum tweet length: {}\".format(max(tweets_lens)))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum tweet length: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV5Qg-akkFkL",
        "colab_type": "text"
      },
      "source": [
        "4. Make array with padding of zeros, with each array the size of the longest tweet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hSyKf66i50F",
        "colab_type": "code",
        "outputId": "4052e711-6973-4da2-ff10-b568d979c5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "seq_len = 19\n",
        "features = np.zeros((len(tweets_ints), seq_len), dtype=int)\n",
        "for i, row in enumerate(tweets_ints):\n",
        "  features[i, -len(row):] = np.array(row)[:seq_len]\n",
        "features[:3,:seq_len]"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "         643, 1013,   15,    3,    1, 1793,   17, 5840],\n",
              "       [   0,    0,    0,    4, 3686,  103,  243,   11,  690,   20,    5,\n",
              "           1, 1794,   25,   53, 1552,   60, 5841,   49],\n",
              "       [ 236,  487,    7,  399, 2157, 1111, 2687, 2688, 2689, 2690, 1217,\n",
              "        1014, 2691,   11,  743, 2158,  148,  146,    2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07jxUU1Yjhhf",
        "colab_type": "code",
        "outputId": "6cb52789-c9a2-46c4-9b52-29600522c650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print(\"Number of features: \\t{}\".format(len(features)),\n",
        "      \"\\nSample of feature: \\t{}\".format(features[0]))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features: \t5705 \n",
            "Sample of feature: \t[   0    0    0    0    0    0    0    0    0    0    0  643 1013   15\n",
            "    3    1 1793   17 5840]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUdmWtItk1XC",
        "colab_type": "text"
      },
      "source": [
        "6. Create the training/validation/testing sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-OVCgPPqYDx",
        "colab_type": "code",
        "outputId": "e87e2eb5-090f-4ce0-b2cd-355ef75fea36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "split_frac = 0.9\n",
        "\n",
        "split_index = int(split_frac * len(features))\n",
        "\n",
        "train_x, val_x = features[:split_index], features[split_index:] \n",
        "train_y, val_y = labels[:split_index], labels[split_index:]\n",
        "\n",
        "split_frac = 0.5\n",
        "split_index = int(split_frac * len(val_x))\n",
        "\n",
        "val_x, test_x = val_x[:split_index], val_x[split_index:]\n",
        "val_y, test_y = val_y[:split_index], val_y[split_index:]\n",
        "\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(5134, 19) \n",
            "Validation set: \t(285, 19) \n",
            "Test set: \t\t(286, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOIMsNuSmf7r",
        "colab_type": "text"
      },
      "source": [
        "7. Define the constants for the training process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDqr93dbmgHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_size = 256       # number of units in hidden layers in the LSTM cells\n",
        "lstm_layers = 2       # number of LSTM layers\n",
        "batch_size = 64       # number of tweets to give network in one training batch\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5vq3fXtmoVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_words = len(vocab_to_int) + 1 # add 1 for 0 added to vocab\n",
        "\n",
        "graph = tf.Graph()\n",
        "# add nodes\n",
        "with graph.as_default():\n",
        "    inputs_ = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
        "    labels_ = tf.placeholder(tf.int32, [None, None], name='labels')\n",
        "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_tr1LCRkPPm",
        "colab_type": "text"
      },
      "source": [
        "8. Add embedding layer (letting network learn the weights):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHrdYJYwnp-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300     # number of units in embedding layer\n",
        "\n",
        "with graph.as_default():\n",
        "    embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
        "    embed = tf.nn.embedding_lookup(embedding, inputs_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojBuA_WJkIK6",
        "colab_type": "text"
      },
      "source": [
        "9. Set up the basics of the LSTM cells and RNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pbn7w2_yPxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "    with tf.name_scope(\"RNN_layers\"):\n",
        "        def lstm_cell():\n",
        "            lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, reuse=tf.get_variable_scope().reuse)\n",
        "            return tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob) # add dropout to the cell\n",
        "\n",
        "        # create the multiple LSTM layer stack, for deep learning\n",
        "        cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(lstm_layers)])\n",
        "\n",
        "        # assign initial state of all zeros\n",
        "        initial_state = cell.zero_state(batch_size, tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehs5OGErkz8X",
        "colab_type": "text"
      },
      "source": [
        "10. RNN forward pass from initial state; returns output from each time step and hidden layer's final state:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGu82WNtyXV_",
        "colab_type": "code",
        "outputId": "9fc22710-a35f-4f86-aeec-d145dc3ff185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "with graph.as_default():\n",
        "    outputs, final_state = tf.nn.dynamic_rnn(cell, embed,\n",
        "                                             initial_state=initial_state)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fb98a2a08d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fb98a2a08d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fb98a2a08d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fb98a2a08d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fb98a2a0588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fb98a2a0588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fb98a2a0588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fb98a2a0588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fb98a2a06d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fb98a2a06d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fb98a2a06d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fb98a2a06d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tv2JY72lGmR",
        "colab_type": "text"
      },
      "source": [
        "11. Use the final output as the prediction for the sentiment value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQp741kZyXeR",
        "colab_type": "code",
        "outputId": "4d724c79-0931-4b5d-843f-eb1fa2d3df74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "with graph.as_default():\n",
        "    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
        "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb98540a748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb98540a748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb98540a748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb98540a748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5dyt_mklUHx",
        "colab_type": "text"
      },
      "source": [
        "12. Create nodes to validate the accuracy of the batch and obtain confusion matrix of individual batches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2cTQ9B9yXoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "    correct_prediction = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
        "    #correct_prediction = tf.cast(correct_pred, dtype=tf.bool)\n",
        "    false_prediction = tf.logical_not(correct_prediction)\n",
        "\n",
        "    is_label_one = tf.cast(labels_, dtype=tf.bool) #tf.ones([1], tf.int32)\n",
        "    is_label_zero = tf.logical_not(is_label_one)\n",
        "\n",
        "    true_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction,is_label_one)))\n",
        "    false_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, is_label_zero)))\n",
        "    true_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, is_label_zero)))\n",
        "    false_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, is_label_one)))\n",
        "\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "    recall = true_positives / (true_positives + false_negatives)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umynM0XWlj0i",
        "colab_type": "text"
      },
      "source": [
        "13. Train the model in batches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WPCzBh41BbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(x, y, batch_size=64):\n",
        "    \n",
        "    n_batches = len(x)//batch_size\n",
        "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
        "    for i in range(0, len(x), batch_size):\n",
        "        yield x[i:i+batch_size], y[i:i+batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j1LywySyg9k",
        "colab_type": "code",
        "outputId": "a44b80aa-42b2-4a4a-fc4c-ce9f0e81c076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "with graph.as_default():\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session(graph=graph) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    iteration = 1\n",
        "    for e in range(1, epochs+1):\n",
        "        state = sess.run(initial_state)\n",
        "        \n",
        "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
        "            feed = {inputs_: x,\n",
        "                    labels_: y[:, None],\n",
        "                    keep_prob: 0.5,\n",
        "                    initial_state: state}\n",
        "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
        "            \n",
        "            if iteration%5==0:\n",
        "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
        "                      \"Iteration: {}\".format(iteration),\n",
        "                      \"Train loss: {:.3f}\".format(loss))\n",
        "\n",
        "            if iteration%25==0:\n",
        "                val_acc = []\n",
        "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
        "                for x, y in get_batches(val_x, val_y, batch_size):\n",
        "                    feed = {inputs_: x,\n",
        "                            labels_: y[:, None],\n",
        "                            keep_prob: 1,\n",
        "                            initial_state: val_state}\n",
        "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
        "                    val_acc.append(batch_acc)\n",
        "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
        "            iteration +=1\n",
        "            saver.save(sess, \"checkpoints/sentiment.ckpt\")\n",
        "    saver.save(sess, \"checkpoints/sentiment.ckpt\")"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/5 Iteration: 5 Train loss: 0.341\n",
            "Epoch: 1/5 Iteration: 10 Train loss: 0.262\n",
            "Epoch: 1/5 Iteration: 15 Train loss: 0.248\n",
            "Epoch: 1/5 Iteration: 20 Train loss: 0.334\n",
            "Epoch: 1/5 Iteration: 25 Train loss: 0.239\n",
            "Val acc: 0.480\n",
            "Epoch: 1/5 Iteration: 30 Train loss: 0.279\n",
            "Epoch: 1/5 Iteration: 35 Train loss: 0.264\n",
            "Epoch: 1/5 Iteration: 40 Train loss: 0.236\n",
            "Epoch: 1/5 Iteration: 45 Train loss: 0.252\n",
            "Epoch: 1/5 Iteration: 50 Train loss: 0.255\n",
            "Val acc: 0.469\n",
            "Epoch: 1/5 Iteration: 55 Train loss: 0.246\n",
            "Epoch: 1/5 Iteration: 60 Train loss: 0.277\n",
            "Epoch: 1/5 Iteration: 65 Train loss: 0.276\n",
            "Epoch: 1/5 Iteration: 70 Train loss: 0.240\n",
            "Epoch: 1/5 Iteration: 75 Train loss: 0.239\n",
            "Val acc: 0.477\n",
            "Epoch: 1/5 Iteration: 80 Train loss: 0.245\n",
            "Epoch: 2/5 Iteration: 85 Train loss: 0.250\n",
            "Epoch: 2/5 Iteration: 90 Train loss: 0.252\n",
            "Epoch: 2/5 Iteration: 95 Train loss: 0.223\n",
            "Epoch: 2/5 Iteration: 100 Train loss: 0.260\n",
            "Val acc: 0.535\n",
            "Epoch: 2/5 Iteration: 105 Train loss: 0.225\n",
            "Epoch: 2/5 Iteration: 110 Train loss: 0.220\n",
            "Epoch: 2/5 Iteration: 115 Train loss: 0.211\n",
            "Epoch: 2/5 Iteration: 120 Train loss: 0.201\n",
            "Epoch: 2/5 Iteration: 125 Train loss: 0.177\n",
            "Val acc: 0.598\n",
            "Epoch: 2/5 Iteration: 130 Train loss: 0.197\n",
            "Epoch: 2/5 Iteration: 135 Train loss: 0.183\n",
            "Epoch: 2/5 Iteration: 140 Train loss: 0.177\n",
            "Epoch: 2/5 Iteration: 145 Train loss: 0.219\n",
            "Epoch: 2/5 Iteration: 150 Train loss: 0.167\n",
            "Val acc: 0.652\n",
            "Epoch: 2/5 Iteration: 155 Train loss: 0.161\n",
            "Epoch: 2/5 Iteration: 160 Train loss: 0.141\n",
            "Epoch: 3/5 Iteration: 165 Train loss: 0.153\n",
            "Epoch: 3/5 Iteration: 170 Train loss: 0.146\n",
            "Epoch: 3/5 Iteration: 175 Train loss: 0.084\n",
            "Val acc: 0.684\n",
            "Epoch: 3/5 Iteration: 180 Train loss: 0.078\n",
            "Epoch: 3/5 Iteration: 185 Train loss: 0.126\n",
            "Epoch: 3/5 Iteration: 190 Train loss: 0.076\n",
            "Epoch: 3/5 Iteration: 195 Train loss: 0.104\n",
            "Epoch: 3/5 Iteration: 200 Train loss: 0.086\n",
            "Val acc: 0.645\n",
            "Epoch: 3/5 Iteration: 205 Train loss: 0.051\n",
            "Epoch: 3/5 Iteration: 210 Train loss: 0.054\n",
            "Epoch: 3/5 Iteration: 215 Train loss: 0.028\n",
            "Epoch: 3/5 Iteration: 220 Train loss: 0.056\n",
            "Epoch: 3/5 Iteration: 225 Train loss: 0.094\n",
            "Val acc: 0.699\n",
            "Epoch: 3/5 Iteration: 230 Train loss: 0.061\n",
            "Epoch: 3/5 Iteration: 235 Train loss: 0.038\n",
            "Epoch: 3/5 Iteration: 240 Train loss: 0.037\n",
            "Epoch: 4/5 Iteration: 245 Train loss: 0.023\n",
            "Epoch: 4/5 Iteration: 250 Train loss: 0.067\n",
            "Val acc: 0.672\n",
            "Epoch: 4/5 Iteration: 255 Train loss: 0.036\n",
            "Epoch: 4/5 Iteration: 260 Train loss: 0.001\n",
            "Epoch: 4/5 Iteration: 265 Train loss: 0.050\n",
            "Epoch: 4/5 Iteration: 270 Train loss: 0.060\n",
            "Epoch: 4/5 Iteration: 275 Train loss: 0.032\n",
            "Val acc: 0.676\n",
            "Epoch: 4/5 Iteration: 280 Train loss: 0.054\n",
            "Epoch: 4/5 Iteration: 285 Train loss: 0.023\n",
            "Epoch: 4/5 Iteration: 290 Train loss: 0.054\n",
            "Epoch: 4/5 Iteration: 295 Train loss: 0.001\n",
            "Epoch: 4/5 Iteration: 300 Train loss: 0.020\n",
            "Val acc: 0.645\n",
            "Epoch: 4/5 Iteration: 305 Train loss: 0.029\n",
            "Epoch: 4/5 Iteration: 310 Train loss: 0.034\n",
            "Epoch: 4/5 Iteration: 315 Train loss: 0.007\n",
            "Epoch: 4/5 Iteration: 320 Train loss: 0.037\n",
            "Epoch: 5/5 Iteration: 325 Train loss: 0.009\n",
            "Val acc: 0.676\n",
            "Epoch: 5/5 Iteration: 330 Train loss: 0.055\n",
            "Epoch: 5/5 Iteration: 335 Train loss: 0.021\n",
            "Epoch: 5/5 Iteration: 340 Train loss: 0.011\n",
            "Epoch: 5/5 Iteration: 345 Train loss: 0.065\n",
            "Epoch: 5/5 Iteration: 350 Train loss: 0.053\n",
            "Val acc: 0.648\n",
            "Epoch: 5/5 Iteration: 355 Train loss: 0.008\n",
            "Epoch: 5/5 Iteration: 360 Train loss: 0.027\n",
            "Epoch: 5/5 Iteration: 365 Train loss: 0.028\n",
            "Epoch: 5/5 Iteration: 370 Train loss: 0.037\n",
            "Epoch: 5/5 Iteration: 375 Train loss: 0.021\n",
            "Val acc: 0.629\n",
            "Epoch: 5/5 Iteration: 380 Train loss: 0.008\n",
            "Epoch: 5/5 Iteration: 385 Train loss: 0.018\n",
            "Epoch: 5/5 Iteration: 390 Train loss: 0.018\n",
            "Epoch: 5/5 Iteration: 395 Train loss: 0.002\n",
            "Epoch: 5/5 Iteration: 400 Train loss: 0.026\n",
            "Val acc: 0.676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXPOjwd2lx-T",
        "colab_type": "text"
      },
      "source": [
        "14. Test the model, listing all predictions and then obtaining the average:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHnK6K1RyhQi",
        "colab_type": "code",
        "outputId": "e960642c-91b9-4990-d814-c70259ee88f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "test_acc = []\n",
        "test_prec = []\n",
        "test_rec = []\n",
        "\n",
        "with tf.Session(graph=graph) as sess:\n",
        "    saver.restore(sess, \"checkpoints/sentiment.ckpt\")\n",
        "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
        "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
        "        feed = {inputs_: x,\n",
        "                labels_: y[:, None],\n",
        "                keep_prob: 1,\n",
        "                initial_state: test_state}\n",
        "        batch_acc, batch_prec, batch_rec = sess.run([accuracy, precision, recall], feed_dict=feed)\n",
        "\n",
        "        test_acc.append(batch_acc)\n",
        "        test_prec.append(batch_prec)\n",
        "        test_rec.append(batch_rec)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from checkpoints/sentiment.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMCggtz9FnMG",
        "colab_type": "code",
        "outputId": "e872d2bd-0c96-4064-f502-b4fa9e77caf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "prec = np.mean(test_prec)\n",
        "rec = np.mean(test_rec)\n",
        "acc = np.mean(test_acc)\n",
        "print(\"Test precision: {:.3f}\".format(prec))\n",
        "print(\"Test recall: {:.3f}\".format(rec))\n",
        "print(\"Test accuracy: {:.3f}\".format(acc))\n",
        "print(\"Test F1 score: {:.3f}\".format(2*((prec*rec) / (prec+rec))))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test precision: 0.739\n",
            "Test recall: 0.746\n",
            "Test accuracy: 0.656\n",
            "Test F1 score: 0.743\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}