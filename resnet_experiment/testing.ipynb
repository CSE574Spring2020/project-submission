{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "data_path = '/home/afuchs/ub-cse474-s20/cse4574/data/ims/ads/'\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "data_dir = pathlib.Path(data_path)\n",
    "class_name_list = [f.name for f in data_dir.glob('*')]\n",
    "\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "\n",
    "# # display each image\n",
    "# for image_path in data_dir.glob('*/*.jpg'):\n",
    "#     image = Image.open(image_path)\n",
    "#     display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 720 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_generator = image_data_generator.flow_from_directory(\n",
    "    directory=str(data_dir),\n",
    "    class_mode='binary',\n",
    "#     color_mode='grayscale',\n",
    "    # batch_size=0,\n",
    "    # shuffle=True,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    classes=class_name_list,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 2.3990 - accuracy: 0.0625\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 151us/sample - loss: 2.3910 - accuracy: 0.1875\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 155us/sample - loss: 2.3842 - accuracy: 0.1875\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 134us/sample - loss: 2.3770 - accuracy: 0.1875\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 190us/sample - loss: 2.3694 - accuracy: 0.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90407f3210>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Most of this is from the CSE 4/574 NN_Example.py example code and\n",
    "    # TensorFlow's documentation\n",
    "    # https://piazza.com/class_profile/get_resource/k5obys2ajh66dx/k83psp6rubdj3\n",
    "    # https://www.tensorflow.org/tutorials/keras/classification\n",
    "\n",
    "# define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(11, activation=tf.nn.softmax),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# train the model\n",
    "train_images, train_labels = next(train_data_generator)\n",
    "train_images /= 255.0\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
